{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WizardOZ/PDL_Practicas/blob/main/Practica3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Csqh-FUEOn8Q",
        "outputId": "6a2c08ea-283c-48f4-e910-8f78b22d2725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.6)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.10.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.5.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.16.0)\n",
            "Requirement already satisfied: language_tool_python in /usr/local/lib/python3.10/dist-packages (2.8.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (4.66.6)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (0.45.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install spacy\n",
        "!pip install textblob\n",
        "!pip install gensim\n",
        "!pip install scikit-learn\n",
        "!pip install pyLDAvis\n",
        "!pip install language_tool_python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOKENIZACIÓN Y ETIQUETADO POST\n",
        "\n",
        "Por un lado podemos usar \"nltk.word_tokenize(text)\" para dividir un texto en unidades más pequeñas.\n",
        "\n",
        "Mientras si usamos \"nltk.pos_tag(tokens)\" además, clasifica a cada palabra en su categoria gramatical.\n"
      ],
      "metadata": {
        "id": "FfCpOkkgS5qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# Ejemplo de texto en inglés\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenización - Léxico\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Etiquetado POS con NLTK - Sintáctico\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(\"Etiquetas POS:\", pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBWirBquPe21",
        "outputId": "8940222c-3a64-4e58-d9a0-751d2cc171bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
            "Etiquetas POS: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VISUALIZACIÓN CON Spacy\n",
        "\n",
        "Muestra una representación visual del **Árbol de dependencias**"
      ],
      "metadata": {
        "id": "OMDl_9SjScf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Necesitamos el modelo en español porque cada idioma tiene su propia estructura gramatical y reglas sintácticas.\n",
        "   Un modelo preentrenado en español como el de SpaCy puede realizar estas tareas de etiquetado gramatical y análisis sintáctico con precisión,\n",
        "   porque ha sido entrenado en los patrones lingüísticos específicos de este idioma.'''\n",
        "!python -m spacy download es_core_news_sm #decarga el modelo español de spacy (terminal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmlDoys6QI1e",
        "outputId": "7b3409b3-c872-4de2-c03e-9f98b0f71d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# Cargar el modelo en español\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Texto de ejemplo\n",
        "text = 'The quick brown fox jumps over the lazy dog.'\n",
        "\n",
        "# Procesar el texto\n",
        "doc = nlp(text)\n",
        "\n",
        "# Visualizar el árbol de dependencias, incluyendo etiquetas POS\n",
        "displacy.render(doc, style='dep', jupyter=True, options={'distance': 100})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "VsQGz7BvQL0R",
        "outputId": "81870faa-ca9d-4e8c-92d7-5a9fa21ef41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"3f651a64c6f04c9bb4820e79f31cbc0b-0\" class=\"displacy\" width=\"950\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">quick</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">brown</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">fox</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">jumps</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">over</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">lazy</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">dog.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-0\" stroke-width=\"2px\" d=\"M70,152.0 C70,2.0 350.0,2.0 350.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,154.0 L62,142.0 78,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-1\" stroke-width=\"2px\" d=\"M170,152.0 C170,52.0 345.0,52.0 345.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M170,154.0 L162,142.0 178,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-2\" stroke-width=\"2px\" d=\"M270,152.0 C270,102.0 340.0,102.0 340.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M270,154.0 L262,142.0 278,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-3\" stroke-width=\"2px\" d=\"M370,152.0 C370,102.0 440.0,102.0 440.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M370,154.0 L362,142.0 378,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-4\" stroke-width=\"2px\" d=\"M470,152.0 C470,102.0 540.0,102.0 540.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M540.0,154.0 L548.0,142.0 532.0,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-5\" stroke-width=\"2px\" d=\"M670,152.0 C670,52.0 845.0,52.0 845.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M670,154.0 L662,142.0 678,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-6\" stroke-width=\"2px\" d=\"M770,152.0 C770,102.0 840.0,102.0 840.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,154.0 L762,142.0 778,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-7\" stroke-width=\"2px\" d=\"M570,152.0 C570,2.0 850.0,2.0 850.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3f651a64c6f04c9bb4820e79f31cbc0b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M850.0,154.0 L858.0,142.0 842.0,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LEMATIZACIÓN\n",
        "\n",
        "Usamos la libreria Spacy para lematizar las palabras.\n",
        "\n",
        "Cuando lematizamos, reducimos una palabra a su forma base o lema.\n"
      ],
      "metadata": {
        "id": "KwMu_alJR_6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "!python -m spacy download es_core_news_sm\n",
        "# Cargar modelo en español\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "# Texto de ejemplo\n",
        "text = 'Apple fue fundada por Steve Jobs en California.'\n",
        "\n",
        "# Procesar el texto\n",
        "doc = nlp(text)\n",
        "\n",
        "# Lematización - Léxico\n",
        "print('Lemas:')\n",
        "for token in doc:\n",
        "    print(f'{token.text} -> {token.lemma_}')\n",
        "\n",
        "# Visualización de Entidades Nombradas - léxico/semántico\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "up7Ar8azRVgE",
        "outputId": "6b203e88-44a0-4918-c8dc-0ecfb38f09fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Lemas:\n",
            "Apple -> Apple\n",
            "fue -> ser\n",
            "fundada -> fundar\n",
            "por -> por\n",
            "Steve -> Steve\n",
            "Jobs -> Jobs\n",
            "en -> en\n",
            "California -> California\n",
            ". -> .\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " fue fundada por \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Steve Jobs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " en \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    California\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANALISIS DE SENTIMIENTO Y CORRECIÓN GRAMATICAL\n",
        "\n",
        "Análisis del texto: Mide la polaridad del texto.\n",
        "\n",
        "Correción gramtical: Asegura la claridad y precisión del texto."
      ],
      "metadata": {
        "id": "xG4HT2JPTRBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Example text\n",
        "text = 'This product is absolutely wonderful.'\n",
        "blob = TextBlob(text)\n",
        "\n",
        "# Sentiment Analysis\n",
        "sentiment = blob.sentiment\n",
        "print(f'Polarity: {sentiment.polarity}, Subjectivity: {sentiment.subjectivity}')\n",
        "'''\n",
        "La frase tiene un sentimiento extremadamente positivo,\n",
        "por lo que la polaridad debería estar cerca de 1.0.\n",
        "Dado que la frase expresa una opinión subjetiva sobre el producto,\n",
        "la subjetividad también debería ser alta, cerca de 1.0\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "WhcSVcJ1TnJ9",
        "outputId": "3bc867fb-9c45-4a1e-9ce6-01c23d29db58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity: 1.0, Subjectivity: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nLa frase tiene un sentimiento extremadamente positivo,\\npor lo que la polaridad debería estar cerca de 1.0.\\nDado que la frase expresa una opinión subjetiva sobre el producto,\\nla subjetividad también debería ser alta, cerca de 1.0\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTACIÓN LANGUAGE TOOL -- Correción gramatical\n",
        "\n"
      ],
      "metadata": {
        "id": "qpefuyQGT0mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install language_tool_python\n",
        "import language_tool_python\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "text_with_errors = \"She go to the market and buy apples.\"\n",
        "\n",
        "# Aplicar la corrección\n",
        "matches = tool.check(text_with_errors)\n",
        "corrected_text = language_tool_python.utils.correct(text_with_errors, matches)\n",
        "\n",
        "print(\"Original text:\", text_with_errors)\n",
        "print(\"Corrected text:\", corrected_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG8T7OAnUBza",
        "outputId": "26b01445-64cb-459c-de33-c3bf3d0bc18c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading LanguageTool 6.4: 100%|██████████| 246M/246M [00:10<00:00, 23.4MB/s]\n",
            "INFO:language_tool_python.download_lt:Unzipping /tmp/tmpxvhd4v50.zip to /root/.cache/language_tool_python.\n",
            "INFO:language_tool_python.download_lt:Downloaded https://www.languagetool.org/download/LanguageTool-6.4.zip to /root/.cache/language_tool_python.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: She go to the market and buy apples.\n",
            "Corrected text: She goes to the market and buy apples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOLSA DE PALABRAS Y TF-IDF(Análisis léxico - Gensim y Scikit-learn)"
      ],
      "metadata": {
        "id": "1ki46ZuiUQzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gensim para Bolsa de Palabras (BoW)\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "# Documentos de ejemplo\n",
        "documents = ['El gato negro saltó sobre el sofá.', 'El perro ladró fuertemente en la casa.']\n",
        "\n",
        "# Tokenización\n",
        "texts = [[word.lower() for word in document.split()] for document in documents]\n",
        "\n",
        "# Creación del diccionario\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "print(\"Diccionario:\", dictionary.token2id)\n",
        "\n",
        "#Creación de la bolsa de palabras\n",
        "corpus_bow = [dictionary.doc2bow(text) for text in texts]\n",
        "print('Bolsa de Palabras:', corpus_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmHuR4tEUgdC",
        "outputId": "70f5db85-142b-4570-e1e4-d6d72ecd3aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diccionario: {'el': 0, 'gato': 1, 'negro': 2, 'saltó': 3, 'sobre': 4, 'sofá.': 5, 'casa.': 6, 'en': 7, 'fuertemente': 8, 'la': 9, 'ladró': 10, 'perro': 11}\n",
            "Bolsa de Palabras: [[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)], [(0, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Representa el caso anterior pero lo divide en un tabla por documento."
      ],
      "metadata": {
        "id": "YrbIPrlJVkn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir corpus_bow a una representación más visual utilizando pandas DataFrame\n",
        "# Creamos una matriz donde las columnas serán las palabras y las filas serán los documentos\n",
        "import pandas as pd\n",
        "data = []\n",
        "\n",
        "for bow in corpus_bow:\n",
        "    bow_dict = dict(bow)\n",
        "    data.append([bow_dict.get(dictionary.token2id[word], 0) for word in dictionary.token2id])\n",
        "\n",
        "# Crear un DataFrame con las palabras como columnas y \"doc 1\", \"doc 2\" como índices\n",
        "doc_names = [f\"doc {i+1}\" for i in range(len(corpus_bow))]\n",
        "df_bow = pd.DataFrame(data, columns=[dictionary[id] for id in range(len(dictionary))], index=doc_names)\n",
        "\n",
        "# Estilo de la tabla con líneas delimitadoras\n",
        "styled_df_bow = df_bow.style.set_table_styles(\n",
        "    [{'selector': 'th', 'props': [('border', '1px solid black')]},\n",
        "     {'selector': 'td', 'props': [('border', '1px solid black')]}]\n",
        ").set_properties(**{'text-align': 'center'})\n",
        "\n",
        "# Mostrar la tabla estilizada\n",
        "styled_df_bow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "LlMrDFNpViMM",
        "outputId": "91b354b0-a0c1-40a2-8157-76445e0ea222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7dfd5ddc0b50>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_60471 th {\n",
              "  border: 1px solid black;\n",
              "}\n",
              "#T_60471 td {\n",
              "  border: 1px solid black;\n",
              "}\n",
              "#T_60471_row0_col0, #T_60471_row0_col1, #T_60471_row0_col2, #T_60471_row0_col3, #T_60471_row0_col4, #T_60471_row0_col5, #T_60471_row0_col6, #T_60471_row0_col7, #T_60471_row0_col8, #T_60471_row0_col9, #T_60471_row0_col10, #T_60471_row0_col11, #T_60471_row1_col0, #T_60471_row1_col1, #T_60471_row1_col2, #T_60471_row1_col3, #T_60471_row1_col4, #T_60471_row1_col5, #T_60471_row1_col6, #T_60471_row1_col7, #T_60471_row1_col8, #T_60471_row1_col9, #T_60471_row1_col10, #T_60471_row1_col11 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_60471\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_60471_level0_col0\" class=\"col_heading level0 col0\" >el</th>\n",
              "      <th id=\"T_60471_level0_col1\" class=\"col_heading level0 col1\" >gato</th>\n",
              "      <th id=\"T_60471_level0_col2\" class=\"col_heading level0 col2\" >negro</th>\n",
              "      <th id=\"T_60471_level0_col3\" class=\"col_heading level0 col3\" >saltó</th>\n",
              "      <th id=\"T_60471_level0_col4\" class=\"col_heading level0 col4\" >sobre</th>\n",
              "      <th id=\"T_60471_level0_col5\" class=\"col_heading level0 col5\" >sofá.</th>\n",
              "      <th id=\"T_60471_level0_col6\" class=\"col_heading level0 col6\" >casa.</th>\n",
              "      <th id=\"T_60471_level0_col7\" class=\"col_heading level0 col7\" >en</th>\n",
              "      <th id=\"T_60471_level0_col8\" class=\"col_heading level0 col8\" >fuertemente</th>\n",
              "      <th id=\"T_60471_level0_col9\" class=\"col_heading level0 col9\" >la</th>\n",
              "      <th id=\"T_60471_level0_col10\" class=\"col_heading level0 col10\" >ladró</th>\n",
              "      <th id=\"T_60471_level0_col11\" class=\"col_heading level0 col11\" >perro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_60471_level0_row0\" class=\"row_heading level0 row0\" >doc 1</th>\n",
              "      <td id=\"T_60471_row0_col0\" class=\"data row0 col0\" >2</td>\n",
              "      <td id=\"T_60471_row0_col1\" class=\"data row0 col1\" >1</td>\n",
              "      <td id=\"T_60471_row0_col2\" class=\"data row0 col2\" >1</td>\n",
              "      <td id=\"T_60471_row0_col3\" class=\"data row0 col3\" >1</td>\n",
              "      <td id=\"T_60471_row0_col4\" class=\"data row0 col4\" >1</td>\n",
              "      <td id=\"T_60471_row0_col5\" class=\"data row0 col5\" >1</td>\n",
              "      <td id=\"T_60471_row0_col6\" class=\"data row0 col6\" >0</td>\n",
              "      <td id=\"T_60471_row0_col7\" class=\"data row0 col7\" >0</td>\n",
              "      <td id=\"T_60471_row0_col8\" class=\"data row0 col8\" >0</td>\n",
              "      <td id=\"T_60471_row0_col9\" class=\"data row0 col9\" >0</td>\n",
              "      <td id=\"T_60471_row0_col10\" class=\"data row0 col10\" >0</td>\n",
              "      <td id=\"T_60471_row0_col11\" class=\"data row0 col11\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_60471_level0_row1\" class=\"row_heading level0 row1\" >doc 2</th>\n",
              "      <td id=\"T_60471_row1_col0\" class=\"data row1 col0\" >1</td>\n",
              "      <td id=\"T_60471_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_60471_row1_col2\" class=\"data row1 col2\" >0</td>\n",
              "      <td id=\"T_60471_row1_col3\" class=\"data row1 col3\" >0</td>\n",
              "      <td id=\"T_60471_row1_col4\" class=\"data row1 col4\" >0</td>\n",
              "      <td id=\"T_60471_row1_col5\" class=\"data row1 col5\" >0</td>\n",
              "      <td id=\"T_60471_row1_col6\" class=\"data row1 col6\" >1</td>\n",
              "      <td id=\"T_60471_row1_col7\" class=\"data row1 col7\" >1</td>\n",
              "      <td id=\"T_60471_row1_col8\" class=\"data row1 col8\" >1</td>\n",
              "      <td id=\"T_60471_row1_col9\" class=\"data row1 col9\" >1</td>\n",
              "      <td id=\"T_60471_row1_col10\" class=\"data row1 col10\" >1</td>\n",
              "      <td id=\"T_60471_row1_col11\" class=\"data row1 col11\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTACION DE SCIKIT-LEARN - TF-IDF\n",
        "\n",
        "**Frecuencia de Término (TF):** Mide cuántas veces aparece una palabra específica en **un** documento.\n",
        "\n",
        "**Frecuencia Inversa de Documentos (IDF):** Mide la rareza de una palabra en el conjunto de documentos. Si una palabra aparece en muchos documentos, su IDF será **baja**, porque es **menos informativa** (palabras comunes como \"el\", \"y\", \"es\").\\\n",
        "**La ponderación TF-IDF**: se calcula multiplicando la TF de la palabra por su IDF. Esto pondera la frecuencia de la palabra según su rareza en el conjunto de documentos.\n",
        "\\\n",
        "**Casos de uso:** Clasificación de Textos, Búsqueda de Información, Filtrado de Palabras Relevantes"
      ],
      "metadata": {
        "id": "OctLuhxuVxOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scikit-learn para TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "documents = [\n",
        "    \"El gato negro saltó sobre el sofá. Luego, el gato descansó cómodamente en su lugar favorito. El gato siempre salta con agilidad.\",\n",
        "    \"El perro ladró fuertemente en la casa. Después, el perro salió a jugar en el jardín. El perro corre rápidamente.\",\n",
        "    \"El gato cazó un ratón en el jardín. Los gatos son excelentes cazadores, siempre al acecho. El gato volvió al sofá.\",\n",
        "    \"El perro dormía plácidamente en su cama. Cuando el perro se despertó, salió corriendo hacia el parque. El perro ama los paseos.\",\n",
        "    \"Los gatos son animales muy independientes. Les gusta dormir durante el día y cazar por la noche. El gato siempre vuelve a casa.\",\n",
        "    \"El perro es conocido por su lealtad hacia los humanos. El perro cuida la casa y siempre está alerta ante cualquier ruido extraño.\",\n",
        "    \"El gato se subió al árbol para escapar del perro. Los gatos son conocidos por su capacidad de trepar y escapar del peligro.\",\n",
        "    \"La computadora se apagó repentinamente mientras estaba ejecutando un programa importante. Después de reiniciarla, todos los archivos volvieron a estar accesibles.\"\n",
        "]\n",
        "\n",
        "# Crear y ajustar el vectorizador TF-IDF\n",
        "vectorizer_tfidf = TfidfVectorizer()\n",
        "X_tfidf = vectorizer_tfidf.fit_transform(documents)\n",
        "\n",
        "# Obtener los nombres de las palabras (vocabulario)\n",
        "feature_names = vectorizer_tfidf.get_feature_names_out()\n",
        "\n",
        "# Convertir la matriz TF-IDF a un DataFrame de pandas\n",
        "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=feature_names)\n",
        "\n",
        "# Añadir nombres de documentos (opcional)\n",
        "df_tfidf.index = [\n",
        "    '1 (gatos)',\n",
        "    '2 (perros)',\n",
        "    '3 (gatos)',\n",
        "    '4 (perros)',\n",
        "    '5 (gatos)',\n",
        "    '6 (perros)',\n",
        "    '7 (gatos)',\n",
        "    '8 (computadoras)'\n",
        "]\n",
        "# Mostrar la tabla\n",
        "print(df_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrUZgVi-WU9W",
        "outputId": "571cfeda-985b-49e8-add5-54cea8bc38f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  accesibles    acecho  agilidad        al   alerta       ama  \\\n",
            "1 (gatos)           0.000000  0.000000  0.225216  0.000000  0.00000  0.000000   \n",
            "2 (perros)          0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
            "3 (gatos)           0.000000  0.246797  0.000000  0.413670  0.00000  0.000000   \n",
            "4 (perros)          0.000000  0.000000  0.000000  0.000000  0.00000  0.230705   \n",
            "5 (gatos)           0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
            "6 (perros)          0.000000  0.000000  0.000000  0.000000  0.24537  0.000000   \n",
            "7 (gatos)           0.000000  0.000000  0.000000  0.186692  0.00000  0.000000   \n",
            "8 (computadoras)    0.240549  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
            "\n",
            "                  animales     ante     apagó  archivos  ...       son  \\\n",
            "1 (gatos)          0.00000  0.00000  0.000000  0.000000  ...  0.000000   \n",
            "2 (perros)         0.00000  0.00000  0.000000  0.000000  ...  0.000000   \n",
            "3 (gatos)          0.00000  0.00000  0.000000  0.000000  ...  0.178482   \n",
            "4 (perros)         0.00000  0.00000  0.000000  0.000000  ...  0.000000   \n",
            "5 (gatos)          0.25528  0.00000  0.000000  0.000000  ...  0.184617   \n",
            "6 (perros)         0.00000  0.24537  0.000000  0.000000  ...  0.000000   \n",
            "7 (gatos)          0.00000  0.00000  0.000000  0.000000  ...  0.161100   \n",
            "8 (computadoras)   0.00000  0.00000  0.240549  0.240549  ...  0.000000   \n",
            "\n",
            "                        su     subió     todos    trepar        un  volvieron  \\\n",
            "1 (gatos)         0.142805  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
            "2 (perros)        0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
            "3 (gatos)         0.000000  0.000000  0.000000  0.000000  0.206835   0.000000   \n",
            "4 (perros)        0.146285  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
            "5 (gatos)         0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
            "6 (perros)        0.155584  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
            "7 (gatos)         0.141249  0.222762  0.000000  0.222762  0.000000   0.000000   \n",
            "8 (computadoras)  0.000000  0.000000  0.240549  0.000000  0.201599   0.240549   \n",
            "\n",
            "                    volvió   vuelve     árbol  \n",
            "1 (gatos)         0.000000  0.00000  0.000000  \n",
            "2 (perros)        0.000000  0.00000  0.000000  \n",
            "3 (gatos)         0.246797  0.00000  0.000000  \n",
            "4 (perros)        0.000000  0.00000  0.000000  \n",
            "5 (gatos)         0.000000  0.25528  0.000000  \n",
            "6 (perros)        0.000000  0.00000  0.000000  \n",
            "7 (gatos)         0.000000  0.00000  0.222762  \n",
            "8 (computadoras)  0.000000  0.00000  0.000000  \n",
            "\n",
            "[8 rows x 97 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MOTOR DE BÚSQUEDA\n",
        "\n",
        "**Consulta:** El usuario ingresa una consulta, en este caso \"gato sofá\".\\\n",
        "**Transformación:** La consulta se transforma en su vector TF-IDF utilizando el mismo vectorizador que ya entrenaste con los documentos.\n",
        "**Similitud de Coseno:** Calculamos la similitud de coseno entre el vector TF-IDF de la consulta y los vectores de TF-IDF de los documentos.\\\n",
        "* Similitud de Coseno: mide cuán similares son dos vectores (en este caso, el vector de la consulta y los vectores de los documentos).\\\n",
        "* El valor varía entre 0 y 1, donde 1 significa documentos idénticos.\\\n",
        "\n",
        "**Resultado:** Mostramos las similitudes de coseno para cada documento y resaltamos cuál es el más relevante."
      ],
      "metadata": {
        "id": "mVMWBkySX7MB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Tu consulta\n",
        "query = \"gato sofá\"\n",
        "\n",
        "# Normalizar la consulta usando el mismo vectorizador TF-IDF que ya has creado\n",
        "query_tfidf = vectorizer_tfidf.transform([query])\n",
        "\n",
        "# Calcular la similitud de coseno entre la consulta y cada documento\n",
        "cosine_similarities = cosine_similarity(query_tfidf, X_tfidf).flatten()\n",
        "\n",
        "# Mostrar las similitudes\n",
        "print(\"Similitud de coseno entre la consulta y los documentos:\")\n",
        "for idx, sim in enumerate(cosine_similarities):\n",
        "    print(f\"Documento {idx + 1}: {sim}\")\n",
        "\n",
        "# Encontrar el documento más relevante\n",
        "most_similar_doc_index = np.argmax(cosine_similarities)\n",
        "print(f\"\\nEl documento más relevante para la consulta '{query}' es el Documento {most_similar_doc_index + 1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4nsM_04YBhA",
        "outputId": "ab9eb7e9-1512-433f-c1f3-fb5ed067ddf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similitud de coseno entre la consulta y los documentos:\n",
            "Documento 1: 0.4090089090150796\n",
            "Documento 2: 0.0\n",
            "Documento 3: 0.3537824405001258\n",
            "Documento 4: 0.0\n",
            "Documento 5: 0.09766441205287543\n",
            "Documento 6: 0.0\n",
            "Documento 7: 0.08522379566333722\n",
            "Documento 8: 0.0\n",
            "\n",
            "El documento más relevante para la consulta 'gato sofá' es el Documento 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EJERCICIO: EXPLORACIÓN DE LA NORMALIZACIÓN EN DISTINTAS LIBRERÍAS"
      ],
      "metadata": {
        "id": "--PV90yFnqsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LIBRERÍA NLTK"
      ],
      "metadata": {
        "id": "H8FVp_wpn-E8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librerias NLTK:"
      ],
      "metadata": {
        "id": "B8u42GjI6m34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U6m6_0I6ph1",
        "outputId": "fe418fc6-30b4-4695-ac58-f53b48253cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Lowercasing**: Convertir todo el texto a minúsculas"
      ],
      "metadata": {
        "id": "50SQKKi1oDoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un texto de ejemplo\n",
        "texto = \"¡The Quick Brown Fox Jumps Over The Lazy Dog!\"\n",
        "\n",
        "# Usamos la función lower() para convertir el texto a minúsculas\n",
        "texto_lower = texto.lower()\n",
        "\n",
        "# Imprimimos el texto original y el texto en minúsculas\n",
        "print(\"Texto original:\", texto)\n",
        "print(\"Texto en minúsculas:\", texto_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf50sHV9-trP",
        "outputId": "d99f1f32-ad27-4eb3-edd8-cecbb684dc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: ¡The Quick Brown Fox Jumps Over The Lazy Dog!\n",
            "Texto en minúsculas: ¡the quick brown fox jumps over the lazy dog!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Eliminar puntuación**: Eliminar signos de puntuación innecesarios"
      ],
      "metadata": {
        "id": "uI9S__NxqE-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de ejemplo con puntuación\n",
        "texto = \"¡The quick brown fox jumps over the lazy dog!\"\n",
        "\n",
        "# Agregar signos de puntuación de apertura (¡ y ¿) a la lista de puntuación\n",
        "punctuation_extended = string.punctuation + \"¡¿\"\n",
        "\n",
        "# Eliminar puntuación utilizando la lista extendida de puntuación\n",
        "texto_sin_puntuacion = ''.join([char for char in texto if char not in punctuation_extended])\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(\"Texto original:\", texto)\n",
        "print(\"Texto sin puntuación:\", texto_sin_puntuacion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcl8bzIPAFJb",
        "outputId": "7ecc5387-6127-4ca5-e1f4-2fc0470c08a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: ¡The quick brown fox jumps over the lazy dog!\n",
            "Texto sin puntuación: The quick brown fox jumps over the lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Eliminar números**: Remover los números que no aporten valor al análisis"
      ],
      "metadata": {
        "id": "lNyfpPfg84Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de ejemplo con números\n",
        "texto = \"The quick brown 22 fox jumps over  5678 the lazy dog\"\n",
        "\n",
        "# Tokenizar el texto en palabras\n",
        "tokens = nltk.word_tokenize(texto)\n",
        "\n",
        "# Filtrar los tokens que no sean números\n",
        "tokens_sin_numeros = [token for token in tokens if not token.isdigit()]\n",
        "\n",
        "# Unir los tokens de nuevo en una cadena\n",
        "texto_sin_numeros = ' '.join(tokens_sin_numeros)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(\"Texto original:\", texto)\n",
        "print(\"Texto sin números:\", texto_sin_numeros)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "148w_0lIBNoC",
        "outputId": "ca155288-5868-4bae-81e6-5850e25ee49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: The quick brown 22 fox jumps over  5678 the lazy dog\n",
            "Texto sin números: The quick brown fox jumps over the lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Eliminar stop words**: Filtrar palabras comunes que no aportan información"
      ],
      "metadata": {
        "id": "jdh1FgjB88El"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de ejemplo\n",
        "texto = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# Tokenizar el texto en palabras\n",
        "tokens = word_tokenize(texto)\n",
        "\n",
        "# Cargar las stop words en español\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Filtrar las stop words\n",
        "tokens_sin_stopwords = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "# Unir los tokens de nuevo en una cadena\n",
        "texto_sin_stopwords = ' '.join(tokens_sin_stopwords)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(\"Texto original:\", texto)\n",
        "print(\"Texto sin stop words:\", texto_sin_stopwords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJNctI7dBzLe",
        "outputId": "2172036e-8da3-4a23-ba3e-f8b7c6a84c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: The quick brown fox jumps over the lazy dog\n",
            "Texto sin stop words: quick brown fox jumps lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Lematización**: Reducir las palabras a su forma base"
      ],
      "metadata": {
        "id": "Z75OlOgJ9AeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un lematizador de NLTK\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Función para convertir etiquetas POS de NLTK a las necesarias para WordNetLemmatizer\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN  # Si no se reconoce, se toma como sustantivo por defecto\n",
        "\n",
        "# Texto de ejemplo\n",
        "texto = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# Tokenización del texto\n",
        "tokens = word_tokenize(texto)\n",
        "\n",
        "# Etiquetar las palabras según su parte del discurso\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "# Lematizar las palabras según sus etiquetas POS\n",
        "lemas = [lemmatizer.lemmatize(token, get_wordnet_pos(tag)) for token, tag in pos_tags]\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Texto original:\", texto)\n",
        "print(\"Lemas:\", lemas)\n",
        "print(\"Texto lematizado:\", ' '.join(lemas))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8qDahhKatpR",
        "outputId": "63b024fb-46c6-4b2b-df3e-5a8e80325c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: The quick brown fox jumps over the lazy dog\n",
            "Lemas: ['The', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazy', 'dog']\n",
            "Texto lematizado: The quick brown fox jump over the lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Stremming**: Aplicar stemming si la librería lo soporta"
      ],
      "metadata": {
        "id": "2e5VFlQ-9CXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un objeto PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Frase de ejemplo\n",
        "texto = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# Tokenizar el texto en palabras\n",
        "tokens = word_tokenize(texto)\n",
        "\n",
        "# Realizar stemming en las palabras tokenizadas\n",
        "stems = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Texto original:\", texto)\n",
        "print(\"Palabras después de stemming:\", stems)\n",
        "print(\"Texto con las palabras raíz:\", ' '.join(stems))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW9DW3OJc0a5",
        "outputId": "5de25095-49b6-4d0e-b7d6-2f1e5d3d57ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: The quick brown fox jumps over the lazy dog\n",
            "Palabras después de stemming: ['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazi', 'dog']\n",
            "Texto con las palabras raíz: the quick brown fox jump over the lazi dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Corrección ortográfica**: Corregir errores ortográficos en el texto. No lo permite diectamente esta biblioteca"
      ],
      "metadata": {
        "id": "wd4IADRp9EOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Tokenización**: Dividir el texto en tokens"
      ],
      "metadata": {
        "id": "r4mUXfA29G9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de texto en inglés\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenización - Léxico\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNERc88y9ktL",
        "outputId": "3272bec0-68b1-4064-8849-980230163e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "dIUcTBM5X83G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LIBRERÍA SPACY"
      ],
      "metadata": {
        "id": "TUQnZaYzYJVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download es_core_news_sm\n",
        "## Librerias necesarias\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load(\"es_core_news_sm\")  # Modelo para español\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4a6b69-390c-4790-f568-96355da1ef88",
        "id": "EuUGWI8lYJVd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Texto de ejemplo\n",
        "texto = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Procesar el texto con SpaCy\n",
        "doc = nlp(texto)\n"
      ],
      "metadata": {
        "id": "S8hJcu3RYJVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Lowercasing**: Convertir todo el texto a minúsculas.\n"
      ],
      "metadata": {
        "id": "_n5tig6dYJVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lowercasing(doc):\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "      token_lower = token.text.lower()\n",
        "      tokens.append(token_lower)\n",
        "    return tokens\n",
        "tokens_lowc = lowercasing(doc)\n",
        "print(tokens_lowc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6349c798-aad4-4839-aec6-024f07357f27",
        "id": "xr48XyMoYJVe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Eliminar puntuación**: Eliminar signos de puntuación innecesarios."
      ],
      "metadata": {
        "id": "rqbgIQyzYJVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminar_punt(doc):\n",
        "  tokens = []\n",
        "  for token in doc:\n",
        "    if not token.is_punct:\n",
        "      tokens.append(token)\n",
        "  return tokens\n",
        "tokens_sinP = eliminar_punt(doc)\n",
        "print(tokens_sinP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f0cebc-bca0-46a3-80ba-4f4866a88269",
        "id": "4OzMCnQ3YJVe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[The, quick, brown, fox, jumps, over, the, lazy, dog]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Eliminar números**: Remover los números que no aporten valor al análisis."
      ],
      "metadata": {
        "id": "kPc_HsQsYJVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminar_num(doc):\n",
        "  tokens = []\n",
        "  for token in doc:\n",
        "    if not token.is_digit:\n",
        "      tokens.append(token)\n",
        "  return tokens\n",
        "tokens_sinNum = eliminar_num(doc)\n",
        "print(tokens_sinNum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c3a698-e201-49d5-8c28-e54d441a6c37",
        "id": "X5vRvilpYJVe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[The, quick, brown, fox, jumps, over, the, lazy, dog, .]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Eliminar stop words**: Filtrar palabras comunes que no aportan información."
      ],
      "metadata": {
        "id": "mYZjWCmDYJVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminar_stopWords(doc):\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "      if not token.is_stop:  # Verifica si no es una stop word\n",
        "          tokens.append(token.text)  # Añade la palabra al resultado\n",
        "    print(tokens)\n"
      ],
      "metadata": {
        "id": "IVj1E2CiYJVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPLEMENTACIÓN DE LOS PRIMEROS PASOS JUNTOS** -- Pasos 1 a 4 --"
      ],
      "metadata": {
        "id": "yvCa-4NsYJVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizar(doc):\n",
        "  #Paso 1: Lowercasing\n",
        "  tokens = []\n",
        "  for token in doc:\n",
        "    # Lowercasing\n",
        "    token_lower = token.text.lower()\n",
        "\n",
        "    # Eliminar puntuación y números\n",
        "    if not token.is_punct and not token.is_digit:\n",
        "\n",
        "    # Eliminar stop words\n",
        "      if not token.is_stop:\n",
        "\n",
        "    # Lematización\n",
        "        token_lemma = token.lemma_\n",
        "        tokens.append(token_lemma)\n",
        "\n",
        "  return tokens\n",
        "\n",
        "tokens_norm = normalizar(doc)\n",
        "print(tokens_norm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605be116-77a4-4352-9f46-dd22f4a6dd71",
        "id": "Qyu57PttYJVf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Lematización**: Reducir las palabras a su forma base.\n"
      ],
      "metadata": {
        "id": "ry8v2Yp8YJVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Lemas:')\n",
        "for token in doc:\n",
        "    print(f'{token.text} -> {token.lemma_}')\n",
        "\n",
        "# Visualización de Entidades Nombradas - léxico/semántico\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "f1e87859-4929-454d-a643-d62101e50738",
        "id": "JKrpVY0JYJVf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemas:\n",
            "The -> The\n",
            "quick -> quick\n",
            "brown -> brown\n",
            "fox -> fox\n",
            "jumps -> jumps\n",
            "over -> over\n",
            "the -> the\n",
            "lazy -> lazy\n",
            "dog -> dog\n",
            ". -> .\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    The quick brown fox jumps\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    over the lazy dog\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  6. **Stemming (opcional)** NO ES APLICABLE EN EL CASO DE ESTA LIBRERÍA"
      ],
      "metadata": {
        "id": "GTvc7vejYJVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Corrección ortográfica**: NO ES APLICABLE EN EL CASO DE ESTA LIBRERÍA"
      ],
      "metadata": {
        "id": "hhOTFteHYJVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Tokenización**: Dividir el texto en tokens.\n"
      ],
      "metadata": {
        "id": "pZpxoKTTYJVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar el árbol de dependencias, incluyendo etiquetas POS\n",
        "displacy.render(doc, style='dep', jupyter=True, options={'distance': 100})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "6736862f-8375-42d6-ce51-872dbde28f71",
        "id": "c7urRM3MYJVg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"es\" id=\"ff5290652a814788b4f5f9d0445a213b-0\" class=\"displacy\" width=\"950\" height=\"387.0\" direction=\"ltr\" style=\"max-width: none; height: 387.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">quick</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">brown</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">fox</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">jumps</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">over</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">lazy</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">dog.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ff5290652a814788b4f5f9d0445a213b-0-0\" stroke-width=\"2px\" d=\"M70,252.0 C70,2.0 550.0,2.0 550.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ff5290652a814788b4f5f9d0445a213b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,254.0 L62,242.0 78,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ff5290652a814788b4f5f9d0445a213b-0-1\" stroke-width=\"2px\" d=\"M70,252.0 C70,202.0 130.0,202.0 130.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ff5290652a814788b4f5f9d0445a213b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">flat</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M130.0,254.0 L138.0,242.0 122.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ff5290652a814788b4f5f9d0445a213b-0-2\" stroke-width=\"2px\" d=\"M70,252.0 C70,152.0 235.0,152.0 235.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ff5290652a814788b4f5f9d0445a213b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">flat</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M235.0,254.0 L243.0,242.0 227.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ff5290652a814788b4f5f9d0445a213b-0-3\" stroke-width=\"2px\" d=\"M70,252.0 C70,102.0 340.0,102.0 340.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ff5290652a814788b4f5f9d0445a213b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">flat</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M340.0,254.0 L348.0,242.0 332.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ff5290652a814788b4f5f9d0445a213b-0-4\" stroke-width=\"2px\" d=\"M70,252.0 C70,52.0 445.0,52.0 445.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ff5290652a814788b4f5f9d0445a213b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">flat</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M445.0,254.0 L453.0,242.0 437.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ff5290652a814788b4f5f9d0445a213b-0-5\" stroke-width=\"2px\" d=\"M570,252.0 C570,202.0 630.0,202.0 630.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ff5290652a814788b4f5f9d0445a213b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M630.0,254.0 L638.0,242.0 622.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ff5290652a814788b4f5f9d0445a213b-0-6\" stroke-width=\"2px\" d=\"M670,252.0 C670,202.0 730.0,202.0 730.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ff5290652a814788b4f5f9d0445a213b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">flat</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M730.0,254.0 L738.0,242.0 722.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ff5290652a814788b4f5f9d0445a213b-0-7\" stroke-width=\"2px\" d=\"M570,252.0 C570,152.0 835.0,152.0 835.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ff5290652a814788b4f5f9d0445a213b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M835.0,254.0 L843.0,242.0 827.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "npOG7M3mYKfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LIBRERÍA TEXTBLOB"
      ],
      "metadata": {
        "id": "qPwobis72cj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob\n",
        "!python -m textblob.download_corpora\n",
        "## Librerias necesarias\n",
        "from textblob import TextBlob\n",
        "import re"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfraSamx53V_",
        "outputId": "efb8a893-6e69-466c-c9c9-bbe05d5b4789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.6)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Texto de ejemplo\n",
        "texto = \"The quick brown fox jumps over the lazy dog 23.\""
      ],
      "metadata": {
        "id": "-AB-yKPYClbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Lowercasing**: Convertir todo el texto a minúsculas.\n"
      ],
      "metadata": {
        "id": "g_ApR7Fe4XJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_min = texto.lower()\n",
        "\n",
        "#Imprimir texto en minusculas\n",
        "print(\"Texto en minúsculas:\", texto_min)"
      ],
      "metadata": {
        "id": "Sy3isGHy40e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc664ff0-ecc2-4b11-875a-1e3e682f057f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto en minúsculas: the quick brown fox jumps over the lazy dog 23.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Eliminar puntuación**: Eliminar signos de puntuación innecesarios."
      ],
      "metadata": {
        "id": "-ee0gtWP4eKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_min_SinP = re.sub(r'[^\\w\\s]', '', texto_min)\n",
        "print(texto_min_SinP)"
      ],
      "metadata": {
        "id": "mvleGieS4z9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a7993f-cc67-4bc0-ea35-5975f830d0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the quick brown fox jumps over the lazy dog 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Eliminar números**: Remover los números que no aporten valor al análisis."
      ],
      "metadata": {
        "id": "W0Riausj4iJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_min_SinP_SinN = re.sub(r'\\d+', '', texto_min_SinP)\n",
        "print(texto_min_SinP_SinN)"
      ],
      "metadata": {
        "id": "IHyOtg544zao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a71524d7-9278-4e2f-ed6f-bf0407dc5e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the quick brown fox jumps over the lazy dog \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Corrección ortográfica**:\n"
      ],
      "metadata": {
        "id": "pK-gvO8PRCk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_corregido = str(TextBlob(texto_min_SinP_SinN).correct())\n",
        "print(texto_corregido)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L65nJVMAaSLK",
        "outputId": "d9cb9232-8075-4880-dfcb-ffa34d7af413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the quick brown fox jumps over the lazy dog \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Eliminar stop words**: Filtrar palabras comunes que no aportan información."
      ],
      "metadata": {
        "id": "j97gCpgp4kR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear objeto TextBlob\n",
        "blob = TextBlob(texto_corregido)\n",
        "\n",
        "# Eliminar stop words (se requiere una lista de stop words personalizada)\n",
        "stop_words = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'])\n",
        "palabras_filtradas = [palabra for palabra in blob.words if palabra not in stop_words]\n",
        "\n",
        "print(palabras_filtradas)"
      ],
      "metadata": {
        "id": "fgkh7HrU4y_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd9b15b-0279-4a4a-ebb4-9796cbc3570b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['quick', 'brown', 'fox', 'jumps', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Lematización**: Reducir las palabras a su forma base.\n"
      ],
      "metadata": {
        "id": "2SlUWwG14mwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " palabras_lematizadas = [palabra.lemmatize() for palabra in palabras_filtradas]\n",
        " print(palabras_lematizadas)"
      ],
      "metadata": {
        "id": "Cz1CuRLu4ygX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7117fc9-b576-42df-e553-cd4fa6b39396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['quick', 'brown', 'fox', 'jump', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  6. **Stemming (opcional)** NO ES APLICABLE EN EL CASO DE ESTA LIBRERÍA"
      ],
      "metadata": {
        "id": "xbS-hX8Y4oKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Tokenización**: Dividir el texto en tokens.\n"
      ],
      "metadata": {
        "id": "5T2MHcHI4qvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_texto = blob.words\n",
        "print(tokens_texto)\n"
      ],
      "metadata": {
        "id": "YjFgkMJ64wpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5081ad-6434-43c5-8abb-8630c42c8d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "SBcWXEEqdaGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LIBRERIA GENSIM"
      ],
      "metadata": {
        "id": "jtn_6sjIdQEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import string\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.parsing.preprocessing import strip_punctuation\n",
        "from gensim.utils import tokenize\n",
        "from gensim.parsing.preprocessing import STOPWORDS"
      ],
      "metadata": {
        "id": "NlVVYl9odqmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Lowercasing**: Convertir todo el texto a minúsculas."
      ],
      "metadata": {
        "id": "Bjt-fZ2YdTiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de ejemplo\n",
        "texto = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Convertir todo el texto a minúsculas usando simple_preprocess de Gensim\n",
        "texto_lowercased = simple_preprocess(texto)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(\"Texto original:\", texto)\n",
        "print(\"Texto en minúsculas:\", ' '.join(texto_lowercased))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMgWjPipdtTy",
        "outputId": "992ea49f-6655-46d5-b108-181634dcd86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: The quick brown fox jumps over the lazy dog.\n",
            "Texto en minúsculas: the quick brown fox jumps over the lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Eliminar puntuación**: Eliminar signos de puntuación innecesarios."
      ],
      "metadata": {
        "id": "qPZQhRmqdxHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de ejemplo\n",
        "texto = \"The quick brown fox, jumps over the lazy dog!\"\n",
        "\n",
        "# Tokenizar el texto sin convertir a minúsculas\n",
        "tokens = texto.split()\n",
        "\n",
        "# Eliminar la puntuación sin cambiar la capitalización\n",
        "tokens_sin_puntuacion = [token for token in tokens if all(char not in string.punctuation for char in token)]\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(\"Texto original:\", texto)\n",
        "print(\"Texto sin puntuación:\", ' '.join(tokens_sin_puntuacion))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA-VvVpod0qV",
        "outputId": "a201a753-1363-4397-d42e-bfd7fd0157b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: The quick brown fox, jumps over the lazy dog!\n",
            "Texto sin puntuación: The quick brown jumps over the lazy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Eliminar números**: Remover los números que no aporten valor al análisis"
      ],
      "metadata": {
        "id": "m-9JWT6uebg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de ejemplo\n",
        "texto = \"The quick brown fox jumps 123 over the lazy dog 456.\"\n",
        "\n",
        "# Tokenizar el texto sin convertir a minúsculas\n",
        "tokens = texto.split()\n",
        "\n",
        "# Eliminar números y signos de puntuación\n",
        "tokens_sin_numeros = [token for token in tokens if not any(char.isdigit() for char in token)]\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(\"Texto original:\", texto)\n",
        "print(\"Texto sin números:\", ' '.join(tokens_sin_numeros))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmK0YgOuemzb",
        "outputId": "3dd86907-5dea-4f34-adc7-781d663f25cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: The quick brown fox jumps 123 over the lazy dog 456.\n",
            "Texto sin números: The quick brown fox jumps over the lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Eliminar stop words**: Filtrar palabras comunes que no aportan información."
      ],
      "metadata": {
        "id": "Wh2HXqWNfSei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de ejemplo\n",
        "texto = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# Convertir todo el texto a minúsculas usando simple_preprocess de Gensim\n",
        "texto_lowercased = simple_preprocess(texto)\n",
        "\n",
        "# Eliminar las stop words usando Gensim\n",
        "texto_sin_stopwords = [palabra for palabra in texto_lowercased if palabra not in STOPWORDS]\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(\"Texto original:\", texto)\n",
        "print(\"Texto sin stop words:\", \" \".join(texto_sin_stopwords))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DDJOVThnhvD",
        "outputId": "67744f80-75e3-44b4-e721-7623d7aa4066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: The quick brown fox jumps over the lazy dog\n",
            "Texto sin stop words: quick brown fox jumps lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Lematización**: Reducir las palabras a su forma base. Gensim no es la herramienta más adecuada, es mejor utilizar Spacy o NLTK."
      ],
      "metadata": {
        "id": "-he0M5hZgB9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Stemming (opcional)**. NO ES APLICABLE EN EL CASO DE ESTA LIBRERÍA"
      ],
      "metadata": {
        "id": "aRHfOEu9hfZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Corrección ortográfica**: Corregir errores ortográficos en el texto. Gensim no está diseñado para realizar una corrección ortográfica de manera directa, ya que está más orientado al procesamiento y modelado de texto en general."
      ],
      "metadata": {
        "id": "gTX4J5NciFeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Tokenización**: Dividir el texto en tokens. Gensim en sí no ofrece una función de tokenización directa, como NLTK o Spacy"
      ],
      "metadata": {
        "id": "NAyVMZrIjses"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de ejemplo\n",
        "texto = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenizar el texto sin convertir a minúsculas\n",
        "tokens = list(tokenize(texto, lowercase=False))\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(\"Texto original:\", texto)\n",
        "print(\"Tokens sin convertir a minúsculas:\", tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nv3RKRYodLx",
        "outputId": "2647dc86-cb2b-481e-df6c-300bd0b6a879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: The quick brown fox jumps over the lazy dog.\n",
            "Tokens sin convertir a minúsculas: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
          ]
        }
      ]
    }
  ]
}